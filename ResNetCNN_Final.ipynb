{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd944026",
   "metadata": {},
   "source": [
    "This is DL Program now:\n",
    "1) I chose Resnet as pretrained model instead of Vision Transformer cuz ViT is pretrained with 14 millions images and needs thousands of images at least to not overfit.\n",
    "Since I have only 1600 images Resnet will be more enough and more accurate because its pretrained only with 1,2M images\n",
    "2) I chose ResNetCNN instead of CNN because it solves the vanishing gradient problem which is explained already\n",
    "3) Program Overview: Load csv Datas for test and train -> Split it into validation and Train data with L2 and Dropout -> Train and Validation -> Prediction for testing -> Printing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8958c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c3dd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Config --------------------\n",
    "BASE_PATH = \"C:/Users/Sami/Desktop/CV\"\n",
    "IMAGE_PATH = os.path.join(BASE_PATH, \"images\")\n",
    "TRAIN_CSV = os.path.join(BASE_PATH, \"train.csv\")\n",
    "TEST_CSV = os.path.join(BASE_PATH, \"test.csv\")\n",
    "SUBMISSION_CSV = \"submission_ResnetCNN.csv\"\n",
    "\n",
    "BATCH_SIZE = 128 # Number of samples per gradient update\n",
    "EPOCHS = 25 #Passthrough the entire dataset 25 times\n",
    "LR = 2.5e-4 # Learning Rate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d028f",
   "metadata": {},
   "source": [
    "Here I defined Dataset class for leaves to load images and labels which I took from Pytorch Website and modified it for the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf6fc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define custom dataset to load images and labels\n",
    "class LeafDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform #Store the transformations to apply\n",
    "        self.is_test = is_test # Flag: True for test set, False for train/val\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) # Return number of images in the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = int(row[\"id\"]) # needed fir image path\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\") \n",
    "\n",
    "        \n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\") # IMPORTANT!!!: I tried convert(\"L\") for grayscale but performance dropped \n",
    "                                                                #because of pretrained weights with RESNET were with RGB images\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img) # Apply transformations\n",
    "\n",
    "        # for test: return only image\n",
    "        if self.is_test:\n",
    "            return img\n",
    "\n",
    "        # for train/val: return image and label\n",
    "        label = torch.tensor(row[\"species_encoded\"], dtype=torch.long)\n",
    "        return img, label  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da72667",
   "metadata": {},
   "source": [
    "Loading CSV Datas same part like GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ea3c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of classes: 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load train/test CSVs and encode species labels into numbers\n",
    "print(\"Device:\", device)\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df[\"species_encoded\"] = le.fit_transform(train_df[\"species\"]) #take the species column and encode it into numbers\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42c03d",
   "metadata": {},
   "source": [
    " Split training data into train and validation sets like GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9746c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split training data into train and validation sets\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(train_df)), test_size=0.15, stratify=train_df[\"species_encoded\"], random_state=42 # test_size=0.15 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b876a",
   "metadata": {},
   "source": [
    "Here where Transformations happen to improve the model for training and validation. For example Randomcrop, RandomhorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f491565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define image transformations for training and validation\n",
    "#Training includes augmentations; validation does not\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize(254),   \n",
    "    transforms.RandomCrop(224), # IMPORTANT!!!: augmentation , # THIS IS CHOSEN ON PURPOSE CUZ RESNET IS PRETRAINED WITH 224x224 IMAGES\n",
    "    transforms.RandomHorizontalFlip(), #IMPORTANT!!!: #augmentation\n",
    "    transforms.ToTensor(),             \n",
    "    transforms.Normalize((0.5,), (0.5,)), #preprocessing just to help neurone trains better\n",
    "])\n",
    "\n",
    "val_tfm = transforms.Compose([\n",
    "    transforms.Resize(254),\n",
    "    transforms.CenterCrop(224), #IMPORTANT!!!: No augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1949382",
   "metadata": {},
   "source": [
    "Create PyTorch datasets and dataloaders for all sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d804bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets and dataloaders for all sets\n",
    "train_ds = LeafDataset(train_df.iloc[train_idx], IMAGE_PATH, train_tfm, is_test=False)\n",
    "val_ds = LeafDataset(train_df.iloc[val_idx], IMAGE_PATH, val_tfm, is_test=False)\n",
    "test_ds = LeafDataset(test_df, IMAGE_PATH, val_tfm, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True) #dataloader organizes data into batches and load them to cpu/gpu\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f22ac",
   "metadata": {},
   "source": [
    "I loaded the model with Dropout and modified the last layer for the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8613892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained ResNet-18 model and adapt it for our classification task\n",
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\") # resnet 18, 50 101  / \n",
    "     # IMPORTANT!!!:Both pretrained with 1,2m,1,2m images  / 11M, 25M parameters(weights and bias). sta3melet hedha khatrou faster w less overfitting\n",
    "\n",
    "# Replace final layer with Dropout used here and last layer modified !!!\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.2), # IMPORTANT!!!: 20% neurones are randomly not fired to reduce overfitting\n",
    "    nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "model = model.to(device) # I move the model to GPU when I use high-performing PC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d26b5",
   "metadata": {},
   "source": [
    "Here loss will be calculated and L2 will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f069637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4) # IMPORTANT!!!: regularization L2 to reduce overfitting like we did with Dropout ,  This is a variant of gradient descent called AdamW\n",
    "loss_func = torch.nn.CrossEntropyLoss()                                     # L2 discourage large weights by adding a penalty to the loss function -> discourage mermorizing/overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657104f",
   "metadata": {},
   "source": [
    "This is the training and validation phase. Here according the epochs the best accuracy will be saved and its model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0dd0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 4.2752, Val Acc: 15.44%\n",
      " -> New best model saved (Val Acc: 15.44%)\n",
      "Epoch [2/25], Loss: 3.0102, Val Acc: 40.94%\n",
      " -> New best model saved (Val Acc: 40.94%)\n",
      "Epoch [3/25], Loss: 2.2719, Val Acc: 48.32%\n",
      " -> New best model saved (Val Acc: 48.32%)\n",
      "Epoch [4/25], Loss: 1.7825, Val Acc: 61.74%\n",
      " -> New best model saved (Val Acc: 61.74%)\n",
      "Epoch [5/25], Loss: 1.4837, Val Acc: 65.10%\n",
      " -> New best model saved (Val Acc: 65.10%)\n",
      "Epoch [6/25], Loss: 1.1789, Val Acc: 70.47%\n",
      " -> New best model saved (Val Acc: 70.47%)\n",
      "Epoch [7/25], Loss: 1.0217, Val Acc: 76.51%\n",
      " -> New best model saved (Val Acc: 76.51%)\n",
      "Epoch [8/25], Loss: 0.8733, Val Acc: 76.51%\n",
      "Epoch [9/25], Loss: 0.7220, Val Acc: 84.56%\n",
      " -> New best model saved (Val Acc: 84.56%)\n",
      "Epoch [10/25], Loss: 0.6602, Val Acc: 83.22%\n",
      "Epoch [11/25], Loss: 0.6159, Val Acc: 86.58%\n",
      " -> New best model saved (Val Acc: 86.58%)\n",
      "Epoch [12/25], Loss: 0.5234, Val Acc: 87.25%\n",
      " -> New best model saved (Val Acc: 87.25%)\n",
      "Epoch [13/25], Loss: 0.4881, Val Acc: 89.93%\n",
      " -> New best model saved (Val Acc: 89.93%)\n",
      "Epoch [14/25], Loss: 0.4428, Val Acc: 89.26%\n",
      "Epoch [15/25], Loss: 0.4265, Val Acc: 87.25%\n",
      "Epoch [16/25], Loss: 0.4034, Val Acc: 91.28%\n",
      " -> New best model saved (Val Acc: 91.28%)\n",
      "Epoch [17/25], Loss: 0.4116, Val Acc: 87.25%\n",
      "Epoch [18/25], Loss: 0.3512, Val Acc: 89.26%\n",
      "Epoch [19/25], Loss: 0.3512, Val Acc: 87.25%\n",
      "Epoch [20/25], Loss: 0.3547, Val Acc: 90.60%\n",
      "Epoch [21/25], Loss: 0.3172, Val Acc: 83.89%\n",
      "Epoch [22/25], Loss: 0.2991, Val Acc: 89.93%\n",
      "Epoch [23/25], Loss: 0.2630, Val Acc: 92.62%\n",
      " -> New best model saved (Val Acc: 92.62%)\n",
      "Epoch [24/25], Loss: 0.2776, Val Acc: 90.60%\n",
      "Epoch [25/25], Loss: 0.2546, Val Acc: 91.95%\n"
     ]
    }
   ],
   "source": [
    "# The training loop with validation and best model saving\n",
    "# IMPORTANT DEF: The gradient tells how much and in which direction to change each weight.\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Training Phase ---\n",
    "    model.train()  # Set model to training mode (enables dropout, etc.)\n",
    "    running_loss = 0.0 # Reset loss accumulator\n",
    "\n",
    "    for X_mb, y_mb in train_loader: #Loop through batches of training data\n",
    "        X_mb, y_mb = X_mb.to(device), y_mb.to(device) # Move batch to GPU when training home\n",
    "        \n",
    "        optimizer.zero_grad()  # Reset gradients from previous batch\n",
    "        y_hat = model(X_mb)    # Forward pass: get predictions  IMPORTANT!!!:\n",
    "        loss = loss_func(y_hat, y_mb) # Caluculation of loss   IMPORTANT!!!:\n",
    "        loss.backward()  # Backward pass: calculate the gradient for every weight in the model  IMPORTANT!!!:\n",
    "        optimizer.step() # here happens gradient descent step: update weights using calculated gradients. The Formula ist new_weight = old_weight - (learning_rate Ã— gradient)  IMPORTANT!!!:\n",
    "        \n",
    "        running_loss += loss.item() # Accumulate loss\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    \n",
    "    for X_mb, y_mb in val_loader: # Loop through validation batches\n",
    "        X_mb, y_mb = X_mb.to(device), y_mb.to(device)\n",
    "        y_hat = model(X_mb) # Get predictions\n",
    "        _, predicted = torch.max(y_hat, 1) # Get class with highest score\n",
    "        total += y_mb.size(0)  # Count total samples ( validated)\n",
    "        correct += (predicted == y_mb).sum().item() # Count correct predictions only if predicted=label\n",
    "\n",
    "    # --- Print Epoch Results and Save Best Model ---\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\") # Save model weights\n",
    "        print(f\" -> New best model saved (Val Acc: {best_val_acc:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd16cb9",
   "metadata": {},
   "source": [
    "Best Validation Accuracy is 92,6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7187be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best validation accuracy: 92.62%\n"
     ]
    }
   ],
   "source": [
    "# Load the highest validation accuracy\n",
    "model.load_state_dict(torch.load(\"best_model.pth\")) # Load the saved best model\n",
    "print(f\"\\nBest validation accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f687322",
   "metadata": {},
   "source": [
    "Here starts Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83f9bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set using the best saved model\n",
    "model.eval()\n",
    "probs_list = []  # List to store predicted probabilities\n",
    "with torch.no_grad():\n",
    "    for imgs in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = model(imgs)   # Get  output scores\n",
    "        probs = torch.softmax(logits, dim=1) # Convert to probabilities (maximum 1)\n",
    "        probs_list.append(probs.cpu().numpy()) # Move to CPU and store as numpy array\n",
    "\n",
    "preds = np.vstack(probs_list) # Stack all batches into one big array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c45c9",
   "metadata": {},
   "source": [
    "Print of submission data with probability of every tested image to be a label\n",
    "See example of Image 16,19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef46e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_ResnetCNN.csv\n"
     ]
    }
   ],
   "source": [
    "# Create and save submission CSV file\n",
    "sub_df = pd.DataFrame(preds, columns=le.classes_)\n",
    "sub_df.insert(0, \"id\", test_df[\"id\"].astype(int))\n",
    "sub_df.to_csv(SUBMISSION_CSV, index=False, float_format=\"%.3f\")\n",
    "print(f\"Saved: {SUBMISSION_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ea995",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
